# url of the db we are trying to connect to
DATABASE_URL="postgres://<userNameHere>@localhost:5432/bloom_prisma"
# port from which the api is accessible
PORT=3100
# google translate api email
GOOGLE_API_EMAIL=
# google translate api id
GOOGLE_API_ID=
# google translate api key
GOOGLE_API_KEY=
# cloudinary secret
CLOUDINARY_SECRET=
# app secret
APP_SECRET="some-long-secret-key"
# url for the proxy
PROXY_URL=
# the node env the app should be running as
NODE_ENV=development
# how long a generated multi-factor authentication code should be
MFA_CODE_LENGTH=5
# TTL for the mfa code, stored in milliseconds
MFA_CODE_VALID=60000
# how long logins are locked after too many failed login attempts in milliseconds
AUTH_LOCK_LOGIN_COOLDOWN=1800000
# how many failed login attempts before a lock occurs
AUTH_LOCK_LOGIN_AFTER_FAILED_ATTEMPTS=5
# phone number for twilio account
TWILIO_PHONE_NUMBER=
# account sid for twilio
TWILIO_ACCOUNT_SID=
# account auth token for twilio
TWILIO_AUTH_TOKEN=
# url for the partner front end
PARTNERS_PORTAL_URL=http://localhost:3001
# controls the repetition of the new afs cron job
DUPLICATES_PROCESSING_CRON_STRING=15 * * * *
# Date the different AFS cron jobs should use to determine which cron job is applicable for the listing
DUPLICATES_CLOSE_DATE="2024-07-28 00:00 -08:00"
# controls the repetition of the afs cron job
AFS_PROCESSING_CRON_STRING=0 * * * *
# controls the repetition of the listing cron job
LISTING_PROCESSING_CRON_STRING=0 * * * *
# controls the repetition of the lottery publish cron job
LOTTERY_PUBLISH_PROCESSING_CRON_STRING=58 23 * * *
# controls the repetition of the lottery cron job
LOTTERY_PROCESSING_CRON_STRING=0 * * * *
# how many days till lottery data expires
LOTTERY_DAYS_TILL_EXPIRY=45
# how many days until application PII data exists
APPLICATION_DAYS_TILL_EXPIRY=
# the list of allowed urls that can make requests to the api (strings must be exact matches)
CORS_ORIGINS=["http://localhost:3000", "http://localhost:3001"]
# spill over list of allowed urls that can make requests to the api (strings are turned into regex)
CORS_REGEX=["test1", "test2"]
# controls the repetition of the temp file clearing cron job
TEMP_FILE_CLEAR_CRON_STRING=0 * * *
# default time zone for dates in exports
TIME_ZONE=America/Los_Angeles
# how long we maintain our request time outs (60 * 60 * 1000 ms)
THROTTLE_TTL=3600000
# how many requests before we throttle
THROTTLE_LIMIT=100
# API passkey, requests missing this will not be alllowed to progress
API_PASS_KEY="some-key-here"
# this is used to test the script runner's data transfer job
TEST_CONNECTION_STRING=""
# recaptcha api key, if set enables recaptcha on backend
RECAPTCHA_KEY=
# needed for recaptcha setup
GOOGLE_CLOUD_PROJECT_ID=
# the score from 0 to 1 that a recaptcha check must pass to continue without 2fa
RECAPTCHA_THRESHOLD=0.7
# if scores should block login flows
ENABLE_RECAPTCHA=TRUE
# controls the repetition of the new afs cron job
DUPLICATES_PROCESSING_CRON_STRING=15 * * * *
# Date the different AFS cron jobs should use to determine which cron job is applicable for the listing
DUPLICATES_CLOSE_DATE="2024-07-28 00:00 -08:00"

# Doorway specific values
ASSET_UPLOAD_MAX_SIZE=
ASSET_FILE_SERVICE=
# public s3 bucket's region (used for files)
ASSET_FS_CONFIG_s3_REGION=
# public s3 bucket (used for files)
ASSET_FS_CONFIG_s3_BUCKET=
# public s3 bucket url format (used for files)
ASSET_FS_CONFIG_s3_URL_FORMAT=public
# private s3 bucket (used for nonpublic files)
ASSET_FS_PRIVATE_CONFIG_s3_BUCKET=
# TTL on secure files
TTL_SECURE_FILES=300000

SITE_EMAIL=
# aws api keys, used for ses
AWS_ACCESS_KEY_ID=
AWS_REGION=us-west-1
COOKIE_DOMAIN=""
# Usually for a dev environment you will want both of these to be true.
# In most cases for prod you would want them to be false
# Although currently doorway requires them to be true in prod, this is a temporary change until
# We have an internal HTTPS cert provider.
# Turns off the requirement for HTTPS only cookies
HTTPS_OFF=true
# Turns on same site cookies
SAME_SITE=true
# Region the s3 bucket used to manage large file transfers (like csv/spreadsheet zips) is set up under
S3_REGION=
# The s3 bucket used to manage large file transfers (like csv/spreadsheet zips)
S3_BUCKET=
# Access key for the service account to the s3 bucket
S3_ACCESS_TOKEN=
# Secret key for the service account to the s3 bucket
S3_SECRET_TOKEN=
